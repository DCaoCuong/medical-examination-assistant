import { NextRequest, NextResponse } from 'next/server';
import Groq from "groq-sdk";

const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });
const DIARIZATION_SERVICE_URL = process.env.DIARIZATION_SERVICE_URL || 'http://localhost:8001';

interface DiarizationSegment {
    start: number;
    end: number;
    speaker: string;
    role?: string;
}

interface DiarizationResponse {
    speakers: DiarizationSegment[];
    num_speakers: number;
    duration: number;
    speaker_mapping?: Record<string, string>;
}

interface TranscriptSegment {
    start: number;
    end: number;
    text: string;
}

interface ProcessedSegment {
    start: number;
    end: number;
    speaker: string;
    role: string;
    raw_text: string;
    clean_text: string;
}

/**
 * G·ªçi Groq Whisper API ƒë·ªÉ chuy·ªÉn audio th√†nh text
 */
async function transcribeWithGroq(audioBlob: Blob): Promise<{ text: string; segments: TranscriptSegment[] }> {
    const groqFormData = new FormData();
    groqFormData.append('file', audioBlob, 'recording.wav');
    groqFormData.append('model', 'whisper-large-v3');
    groqFormData.append('language', 'vi');
    groqFormData.append('response_format', 'verbose_json');

    const response = await fetch('https://api.groq.com/openai/v1/audio/transcriptions', {
        method: 'POST',
        headers: { 'Authorization': `Bearer ${process.env.GROQ_API_KEY}` },
        body: groqFormData,
    });

    if (!response.ok) {
        throw new Error(`Groq API error: ${response.statusText}`);
    }

    const data = await response.json();

    return {
        text: data.text || '',
        segments: data.segments || []
    };
}

/**
 * G·ªçi Python Diarization Service ƒë·ªÉ ph√¢n bi·ªát ng∆∞·ªùi n√≥i
 */
async function getDiarization(audioBlob: Blob): Promise<DiarizationResponse> {
    const formData = new FormData();
    formData.append('file', audioBlob, 'recording.wav');

    const url = `${DIARIZATION_SERVICE_URL}/diarize-with-mapping`;
    console.log(`üé§ Calling diarization service at: ${url}`);

    try {
        // Add timeout of 60 seconds for diarization
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 60000);

        const response = await fetch(url, {
            method: 'POST',
            body: formData,
            signal: controller.signal,
        });

        clearTimeout(timeoutId);

        if (!response.ok) {
            const errorText = await response.text();
            console.warn(`Diarization service error (${response.status}): ${errorText}`);
            return { speakers: [], num_speakers: 0, duration: 0 };
        }

        const result = await response.json();
        console.log(`Diarization success: ${result.num_speakers} speakers found`);
        return result;
    } catch (error) {
        console.warn('Diarization service error:', error);
        // Fallback: return empty diarization
        return { speakers: [], num_speakers: 0, duration: 0 };
    }
}

/**
 * Merge transcript segments v·ªõi diarization results
 */
function mergeTranscriptWithSpeakers(
    transcription: { text: string; segments: TranscriptSegment[] },
    diarization: DiarizationResponse
): { speaker: string; role: string; raw_text: string; start: number; end: number }[] {

    const results: { speaker: string; role: string; raw_text: string; start: number; end: number }[] = [];

    // N·∫øu kh√¥ng c√≥ diarization, g√°n t·∫•t c·∫£ cho 1 speaker m·∫∑c ƒë·ªãnh
    if (diarization.speakers.length === 0) {
        if (transcription.segments.length > 0) {
            for (const seg of transcription.segments) {
                results.push({
                    speaker: 'SPEAKER_00',
                    role: 'Ng∆∞·ªùi n√≥i',
                    raw_text: seg.text,
                    start: seg.start,
                    end: seg.end
                });
            }
        } else if (transcription.text) {
            results.push({
                speaker: 'SPEAKER_00',
                role: 'Ng∆∞·ªùi n√≥i',
                raw_text: transcription.text,
                start: 0,
                end: 0
            });
        }
        return results;
    }

    // N·∫øu c√≥ diarization, match segments
    for (const seg of transcription.segments) {
        const segMid = (seg.start + seg.end) / 2;

        // T√¨m speaker segment ch·ª©a th·ªùi ƒëi·ªÉm gi·ªØa c·ªßa transcript segment
        let matchedSpeaker = diarization.speakers.find(
            sp => sp.start <= segMid && segMid <= sp.end
        );

        // Fallback: t√¨m segment g·∫ßn nh·∫•t
        if (!matchedSpeaker) {
            matchedSpeaker = diarization.speakers.reduce((closest, current) => {
                const closestDist = Math.min(
                    Math.abs(closest.start - segMid),
                    Math.abs(closest.end - segMid)
                );
                const currentDist = Math.min(
                    Math.abs(current.start - segMid),
                    Math.abs(current.end - segMid)
                );
                return currentDist < closestDist ? current : closest;
            }, diarization.speakers[0]);
        }

        results.push({
            speaker: matchedSpeaker?.speaker || 'UNKNOWN',
            role: matchedSpeaker?.role || 'Ng∆∞·ªùi n√≥i',
            raw_text: seg.text,
            start: seg.start,
            end: seg.end
        });
    }

    return results;
}

/**
 * S·ª≠ d·ª•ng Llama 3 ƒë·ªÉ s·ª≠a l·ªói thu·∫≠t ng·ªØ y khoa
 */
async function fixMedicalText(text: string): Promise<string> {
    if (!text || text.trim().length === 0) return text;

    try {
        const chatCompletion = await groq.chat.completions.create({
            messages: [
                {
                    role: "system",
                    content: `B·∫°n l√† chuy√™n gia hi·ªáu ch·ªânh vƒÉn b·∫£n y khoa ti·∫øng Vi·ªát.
Nhi·ªám v·ª•: S·ª≠a l·ªói ch√≠nh t·∫£, ng·ªØ ph√°p v√† thu·∫≠t ng·ªØ y t·∫ø t·ª´ ƒëo·∫°n vƒÉn th√¥ ƒë∆∞·ª£c chuy·ªÉn t·ª´ gi·ªçng n√≥i.
Quy t·∫Øc:
1. Gi·ªØ nguy√™n √Ω nghƒ©a g·ªëc c·ªßa ng∆∞·ªùi n√≥i
2. S·ª≠a c√°c l·ªói ph√°t √¢m th∆∞·ªùng g·∫∑p trong y khoa:
   - "ƒëau th∆∞·ª£ng v·ªãt" ‚Üí "ƒëau th∆∞·ª£ng v·ªã"
   - "ph·∫£i s·ª•p" ‚Üí "s·ªët"
   - "ƒÉn ch√≠ch" ‚Üí "ƒÉn ki√™ng"
3. Chu·∫©n h√≥a thu·∫≠t ng·ªØ y t·∫ø
4. Tr·∫£ v·ªÅ ƒëo·∫°n vƒÉn ƒë√£ s·ª≠a, KH√îNG th√™m l·ªùi d·∫´n hay gi·∫£i th√≠ch`
                },
                { role: "user", content: text }
            ],
            model: "llama-3.3-70b-versatile",
            temperature: 0.1,
            max_tokens: 500
        });

        return chatCompletion.choices[0]?.message?.content || text;
    } catch (error) {
        console.error('Medical fixer error:', error);
        return text;
    }
}

/**
 * Main API Handler - X·ª≠ l√Ω audio v√† tr·∫£ v·ªÅ transcript v·ªõi speaker labels
 */
export async function POST(req: NextRequest) {
    const formData = await req.formData();
    const file = formData.get('file') as Blob;

    if (!file) {
        return NextResponse.json({ error: "No audio file provided" }, { status: 400 });
    }

    try {
        console.log(`üìÅ Received audio: ${file.size} bytes`);

        // Ch·∫°y song song: STT v√† Diarization
        const [transcription, diarization] = await Promise.all([
            transcribeWithGroq(file),
            getDiarization(file)
        ]);

        console.log(`üìù Transcription: ${transcription.text.substring(0, 100)}...`);
        console.log(`üé§ Diarization: ${diarization.num_speakers} speakers found`);

        // N·∫øu kh√¥ng c√≥ text, tr·∫£ v·ªÅ empty
        if (!transcription.text || transcription.text.trim().length === 0) {
            return NextResponse.json({
                success: true,
                segments: [],
                raw_text: "",
                num_speakers: 0
            });
        }

        // Merge transcript v·ªõi speakers
        const mergedSegments = mergeTranscriptWithSpeakers(transcription, diarization);

        // S·ª≠a l·ªói y khoa cho t·ª´ng segment
        const processedSegments: ProcessedSegment[] = await Promise.all(
            mergedSegments.map(async (seg) => ({
                ...seg,
                clean_text: await fixMedicalText(seg.raw_text)
            }))
        );

        return NextResponse.json({
            success: true,
            segments: processedSegments,
            raw_text: transcription.text,
            num_speakers: diarization.num_speakers,
            speaker_mapping: diarization.speaker_mapping || {}
        });

    } catch (error) {
        console.error('‚ùå Processing error:', error);
        return NextResponse.json(
            { error: "L·ªói x·ª≠ l√Ω h·ªá th·ªëng", details: String(error) },
            { status: 500 }
        );
    }
}

/**
 * Health check endpoint
 */
export async function GET() {
    // Check diarization service health
    let diarizationStatus = 'unknown';
    try {
        const response = await fetch(`${DIARIZATION_SERVICE_URL}/health`);
        if (response.ok) {
            const data = await response.json();
            diarizationStatus = data.model_loaded ? 'ready' : 'loading';
        } else {
            diarizationStatus = 'unavailable';
        }
    } catch {
        diarizationStatus = 'unavailable';
    }

    return NextResponse.json({
        status: 'ok',
        services: {
            groq_stt: process.env.GROQ_API_KEY ? 'configured' : 'missing_key',
            diarization: diarizationStatus
        }
    });
}